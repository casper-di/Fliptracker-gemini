name: Train NLP models - Full Pipeline

on:
  workflow_dispatch: {}

jobs:
  data-prep:
    name: Export and Prepare Data
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: Export from Firestore
        working-directory: fliptracker/apps/nlp-service
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/firebase.json
        run: |
          echo "${{ secrets.FIREBASE_SERVICE_ACCOUNT_BASE64 }}" | base64 --decode > "${GOOGLE_APPLICATION_CREDENTIALS}"
          python scripts/validate_json.py "${GOOGLE_APPLICATION_CREDENTIALS}"
          python training/export_data.py

      - name: Prepare data
        working-directory: fliptracker/apps/nlp-service
        run: python training/prepare_data.py

      - name: Check data
        working-directory: fliptracker/apps/nlp-service
        run: |
          echo "=== Training samples ==="
          wc -l data/annotated/spacy_train.json data/annotated/spacy_val.json
          echo ""
          echo "=== Sample entities ==="
          head -30 data/annotated/spacy_train.json

      - name: Archive data
        working-directory: fliptracker/apps/nlp-service
        run: |
          tar -czf prepared-data.tar.gz data/annotated/
          cp prepared-data.tar.gz ../../../

      - name: Upload data artifact
        uses: actions/upload-artifact@v4
        with:
          name: prepared-data
          path: prepared-data.tar.gz
          retention-days: 7

  train:
    name: Train NER Models
    runs-on: ubuntu-latest
    needs: data-prep
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: Download data
        uses: actions/download-artifact@v4
        with:
          name: prepared-data

      - name: Extract data
        run: tar -xzf prepared-data.tar.gz -C fliptracker/apps/nlp-service/

      - name: Create carrier patterns model
        working-directory: fliptracker/apps/nlp-service
        run: python training/create_model.py

      - name: Train address NER model
        working-directory: fliptracker/apps/nlp-service
        run: python training/train_address_ner.py

      - name: Test models
        working-directory: fliptracker/apps/nlp-service
        run: python training/test_models.py

      - name: Collect models
        working-directory: fliptracker/apps/nlp-service
        run: |
          mkdir -p models-final
          cp -r models/ner_model/model-best models-final/carrier
          cp -r models/address_ner/model-best models-final/address
          tar -czf nlp-models.tar.gz models-final/
          cp nlp-models.tar.gz ../../../

      - name: Upload models
        uses: actions/upload-artifact@v4
        with:
          name: nlp-models
          path: nlp-models.tar.gz
          retention-days: 90

      - name: Cleanup
        if: always()
        run: |
          cd fliptracker/apps/nlp-service || true
          rm -rf models models-final || true

  summary:
    name: Summary
    runs-on: ubuntu-latest
    needs: train
    if: always()
    steps:
      - name: Download models
        uses: actions/download-artifact@v4
        with:
          name: nlp-models

      - name: Show results
        run: |
          echo "=========================================="
          echo "ðŸŽ‰ Training Complete!"
          echo "=========================================="
          echo ""
          echo "ðŸ“¦ Models:"
          ls -lh nlp-models.tar.gz || echo "No models"
          echo ""
          echo "âœ… Ready for deployment!"
          echo "=========================================="