name: Train NLP models

on:
  workflow_dispatch: {}

jobs:
  data-prep:
    name: Export and Prepare Data
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsndfile1

      - name: Install PyTorch (CPU)
        run: |
          python -m pip install --upgrade pip
          pip install --index-url https://download.pytorch.org/whl/cpu torch

      - name: Install Python requirements
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: (Optional) Export data from Firestore
        working-directory: fliptracker/apps/nlp-service
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/firebase.json
        run: |
          echo -n "${{ secrets.FIREBASE_SERVICE_ACCOUNT_BASE64 }}" | wc -c > /tmp/secret_len || true
          echo "SECRET_BASE64_BYTES: $(cat /tmp/secret_len)"
          echo "${{ secrets.FIREBASE_SERVICE_ACCOUNT_BASE64 }}" | base64 --decode > "${GOOGLE_APPLICATION_CREDENTIALS}"
          echo "WROTE firebase.json size:" $(wc -c < "${GOOGLE_APPLICATION_CREDENTIALS}" || true)
          ls -l "${GOOGLE_APPLICATION_CREDENTIALS}" || true
          python scripts/validate_json.py "${GOOGLE_APPLICATION_CREDENTIALS}"
          status=$?
          if [ $status -eq 0 ]; then
            echo "firebase.json is valid JSON"
            python training/export_data.py
          else
            echo "firebase.json invalid JSON â€” aborting export"
            echo "First 200 bytes of file (masked):"
            head -c 200 "${GOOGLE_APPLICATION_CREDENTIALS}" | sed -e 's/./*/g'
          fi

      - name: Prepare data (annotate)
        working-directory: fliptracker/apps/nlp-service
        run: python training/prepare_data.py

      - name: Check prepared data size
        run: |
          echo "=== Prepared data size ==="
          du -sh fliptracker/apps/nlp-service/data/annotated || true
          ls -lh fliptracker/apps/nlp-service/data/annotated/*.json || true

      - name: Cleanup disk (data-prep)
        if: always()
        run: |
          sudo apt-get clean
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc || true
          sudo rm -rf /tmp/* ~/.cache/pip || true
          df -h

      - name: Archive prepared data (only annotated .json)
        run: |
          tar -czf prepared-data-${{ github.run_id }}.tar.gz fliptracker/apps/nlp-service/data/annotated/*.json

      - name: Upload prepared data artifact
        uses: actions/upload-artifact@v4
        with:
          name: prepared-data
          path: prepared-data-${{ github.run_id }}.tar.gz
          retention-days: 7

  train:
    name: Train CamemBERT NER + Classifiers
    runs-on: ubuntu-latest
    needs: data-prep
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsndfile1

      - name: Install PyTorch (CPU)
        run: |
          python -m pip install --upgrade pip
          pip install --index-url https://download.pytorch.org/whl/cpu torch

      - name: Install Python requirements
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: Download prepared data artifact
        uses: actions/download-artifact@v4
        with:
          name: prepared-data

      - name: Extract prepared data
        run: |
          mkdir -p fliptracker/apps/nlp-service/data/annotated
          tar -xzf prepared-data-${{ github.run_id }}.tar.gz -C fliptracker/apps/nlp-service/data/annotated --strip-components=5

      - name: Cleanup disk (pre-train)
        run: |
          sudo apt-get clean
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc || true
          sudo rm -rf /tmp/* ~/.cache/pip || true
          df -h

      - name: Train NER + classifiers
        working-directory: fliptracker/apps/nlp-service
        run: |
          python training/train.py --epochs-ner 5 --epochs-cls 3

      - name: Check models directory structure and size
        working-directory: fliptracker/apps/nlp-service
        run: |
          echo "=== Models directory structure ==="
          find models -type d -maxdepth 2 || true
          echo ""
          echo "=== Models size breakdown ==="
          du -sh models/* || true
          echo ""
          echo "=== Total models size ==="
          du -sh models || true
          echo ""
          echo "=== Checkpoint sizes (to be removed) ==="
          find models -name "checkpoint-*" -type d -exec du -sh {} \; || true
          echo ""
          echo "=== Best model sizes (to be kept) ==="
          find models -name "model-best" -type d -exec du -sh {} \; || true

      - name: Collect ONLY best models (production-ready)
        working-directory: fliptracker/apps/nlp-service
        run: |
          set -e
          
          if [ ! -d "models" ]; then
            echo "âŒ No models directory found!"
            exit 1
          fi
          
          # Create a temporary directory for best models only
          mkdir -p models-final
          
          # Copy only model-best directories
          find models -name "model-best" -type d | while read model_path; do
            parent_dir=$(basename $(dirname "$model_path"))
            echo "ðŸ“¦ Copying $parent_dir/model-best"
            mkdir -p "models-final/$parent_dir"
            cp -r "$model_path" "models-final/$parent_dir/"
          done
          
          echo ""
          echo "=== Final models size (only model-best) ==="
          du -sh models-final
          du -sh models-final/*
          
          # Archive only the final models
          tar -czf nlp-models-final-${{ github.run_id }}.tar.gz models-final
          
          echo ""
          echo "=== Archive size ==="
          ls -lh nlp-models-final-${{ github.run_id }}.tar.gz

      - name: Upload production models artifact
        uses: actions/upload-artifact@v4
        with:
          name: nlp-models-production
          path: fliptracker/apps/nlp-service/nlp-models-final-${{ github.run_id }}.tar.gz
          retention-days: 90

      - name: Cleanup (post-train)
        if: always()
        run: |
          cd fliptracker/apps/nlp-service || true
          rm -rf models models-final || true
          rm -f nlp-models-final-*.tar.gz || true
          sudo rm -rf /tmp/* ~/.cache/pip ~/.cache/huggingface || true
          df -h

  summary:
    name: Training Summary
    runs-on: ubuntu-latest
    needs: train
    if: always()
    steps:
      - name: Download production models
        uses: actions/download-artifact@v4
        with:
          name: nlp-models-production

      - name: Show artifact info
        run: |
          echo "=========================================="
          echo "ðŸŽ‰ Training Complete!"
          echo "=========================================="
          echo ""
          echo "ðŸ“¦ Production Models Artifact:"
          ls -lh nlp-models-final-*.tar.gz || echo "No production models found"
          echo ""
          echo "âœ… Models are ready for deployment!"
          echo "ðŸ“¥ Download the 'nlp-models-production' artifact"
          echo ""
          echo "Contents: Only model-best directories"
          echo "  - cls_carrier/model-best/"
          echo "  - cls_email_type/model-best/"
          echo "  - cls_marketplace/model-best/"
          echo "  - cls_type/model-best/"
          echo ""
          echo "âš¡ Checkpoints have been excluded to save space"
          echo "=========================================="