name: Train NLP models

on:
  workflow_dispatch: {}

jobs:
  data-prep:
    name: Export and Prepare Data
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsndfile1

      - name: Install Python requirements
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: Export data from Firestore
        working-directory: fliptracker/apps/nlp-service
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/firebase.json
        run: |
          echo "${{ secrets.FIREBASE_SERVICE_ACCOUNT_BASE64 }}" | base64 --decode > "${GOOGLE_APPLICATION_CREDENTIALS}"
          python scripts/validate_json.py "${GOOGLE_APPLICATION_CREDENTIALS}"
          status=$?
          if [ $status -eq 0 ]; then
            echo "‚úÖ firebase.json is valid"
            python training/export_data.py
          else
            echo "‚ùå firebase.json invalid"
            exit 1
          fi

      - name: Check exported data
        working-directory: fliptracker/apps/nlp-service
        run: |
          if [ -f "data/training_samples.json" ]; then
            echo "‚úÖ training_samples.json found"
            wc -l data/training_samples.json
          else
            echo "‚ùå training_samples.json NOT found"
            exit 1
          fi

      - name: Prepare data
        working-directory: fliptracker/apps/nlp-service
        run: python training/prepare_data.py

      - name: Check prepared data
        working-directory: fliptracker/apps/nlp-service
        run: |
          echo "=== Prepared data files ==="
          ls -lh data/annotated/

      - name: Archive prepared data
        working-directory: fliptracker/apps/nlp-service
        run: |
          tar -czf prepared-data.tar.gz data/annotated/
          cp prepared-data.tar.gz ../../../

      - name: Upload prepared data artifact
        uses: actions/upload-artifact@v4
        with:
          name: prepared-data
          path: prepared-data.tar.gz
          retention-days: 7

  train:
    name: Train spaCy NER Model
    runs-on: ubuntu-latest
    needs: data-prep
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential

      - name: Install Python requirements
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: Download prepared data
        uses: actions/download-artifact@v4
        with:
          name: prepared-data

      - name: Extract prepared data
        run: |
          tar -xzf prepared-data.tar.gz -C fliptracker/apps/nlp-service/

      - name: Inspect training data
        working-directory: fliptracker/apps/nlp-service
        run: python3 << 'PYTHON_SCRIPT'
import json
from pathlib import Path

spacy_file = Path("data/annotated/spacy_train.json")
if spacy_file.exists():
    with open(spacy_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"Total items: {len(data)}")
    
    items_with_entities = 0
    total_entities = 0
    entity_labels = {}
    
    for item in data:
        if isinstance(item, list) and len(item) == 2:
            text, annotations = item
            entities = annotations.get("entities", [])
            
            if entities:
                items_with_entities += 1
                total_entities += len(entities)
                for start, end, label in entities:
                    entity_labels[label] = entity_labels.get(label, 0) + 1
    
    print(f"Items with entities: {items_with_entities}/{len(data)}")
    print(f"Total entities: {total_entities}")
    print(f"\nEntity types:")
    for label, count in sorted(entity_labels.items(), key=lambda x: -x[1]):
        print(f"  {label}: {count}")
    
    if items_with_entities == 0:
        print("\nERROR: No entities found!")
        exit(1)
else:
    print("ERROR: spacy_train.json not found")
    exit(1)
PYTHON_SCRIPT

      - name: Train spaCy NER model
        working-directory: fliptracker/apps/nlp-service
        run: python training/train_spacy_ner.py --epochs 20

      - name: Check model created
        working-directory: fliptracker/apps/nlp-service
        run: |
          if [ -d "models/ner_model/model-best" ]; then
            echo "‚úÖ Model created"
            du -sh models/ner_model/model-best
          else
            echo "‚ùå Model NOT created"
            exit 1
          fi

      - name: Collect model
        working-directory: fliptracker/apps/nlp-service
        run: |
          mkdir -p models-final
          cp -r models/ner_model/model-best models-final/
          tar -czf nlp-ner-model.tar.gz models-final/
          cp nlp-ner-model.tar.gz ../../../

      - name: Upload model artifact
        uses: actions/upload-artifact@v4
        with:
          name: nlp-ner-model
          path: nlp-ner-model.tar.gz
          retention-days: 90

      - name: Cleanup
        if: always()
        run: |
          cd fliptracker/apps/nlp-service || true
          rm -rf models models-final || true

  summary:
    name: Training Summary
    runs-on: ubuntu-latest
    needs: train
    if: always()
    steps:
      - name: Download model
        uses: actions/download-artifact@v4
        with:
          name: nlp-ner-model

      - name: Show result
        run: |
          echo "=========================================="
          echo "üéâ Training Complete!"
          echo "=========================================="
          ls -lh nlp-ner-model.tar.gz || echo "No model found"
          echo "=========================================="