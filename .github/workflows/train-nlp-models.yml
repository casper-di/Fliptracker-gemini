name: Train NLP models

on:
  workflow_dispatch: {}

jobs:
  data-prep:
    name: Export and Prepare Data
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsndfile1

      - name: Install PyTorch (CPU)
        run: |
          python -m pip install --upgrade pip
          pip install --index-url https://download.pytorch.org/whl/cpu torch

      - name: Install Python requirements
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: (Optional) Export data from Firestore
        working-directory: fliptracker/apps/nlp-service
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/firebase.json
        run: |
          echo -n "${{ secrets.FIREBASE_SERVICE_ACCOUNT_BASE64 }}" | wc -c > /tmp/secret_len || true
          echo "SECRET_BASE64_BYTES: $(cat /tmp/secret_len)"
          echo "${{ secrets.FIREBASE_SERVICE_ACCOUNT_BASE64 }}" | base64 --decode > "${GOOGLE_APPLICATION_CREDENTIALS}"
          echo "WROTE firebase.json size:" $(wc -c < "${GOOGLE_APPLICATION_CREDENTIALS}" || true)
          ls -l "${GOOGLE_APPLICATION_CREDENTIALS}" || true
          python scripts/validate_json.py "${GOOGLE_APPLICATION_CREDENTIALS}"
          status=$?
          if [ $status -eq 0 ]; then
            echo "firebase.json is valid JSON"
            python training/export_data.py
          else
            echo "firebase.json invalid JSON â€” aborting export"
            echo "First 200 bytes of file (masked):"
            head -c 200 "${GOOGLE_APPLICATION_CREDENTIALS}" | sed -e 's/./*/g'
          fi

      - name: Prepare data (annotate)
        working-directory: fliptracker/apps/nlp-service
        run: python training/prepare_data.py

      - name: Cleanup disk (data-prep)
        if: always()
        run: |
          sudo apt-get clean
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc || true
          sudo rm -rf /tmp/* ~/.cache/pip || true
          df -h

      - name: Archive prepared data (only annotated .json)
        run: |
          tar -czf prepared-data-${{ github.run_id }}.tar.gz fliptracker/apps/nlp-service/data/annotated/*.json

      - name: Upload prepared data artifact
        uses: actions/upload-artifact@v4
        with:
          name: prepared-data
          path: prepared-data-${{ github.run_id }}.tar.gz

  train:
    name: Train CamemBERT NER + Classifiers
    runs-on: ubuntu-latest
    needs: data-prep
    env:
      PYTHONUNBUFFERED: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsndfile1

      - name: Install PyTorch (CPU)
        run: |
          python -m pip install --upgrade pip
          pip install --index-url https://download.pytorch.org/whl/cpu torch

      - name: Install Python requirements
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: Download prepared data artifact
        uses: actions/download-artifact@v4
        with:
          name: prepared-data

      - name: Extract prepared data
        run: |
          tar -xzf prepared-data-${{ github.run_id }}.tar.gz -C fliptracker/apps/nlp-service

      - name: Cleanup disk (pre-train)
        run: |
          sudo apt-get clean
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc || true
          sudo rm -rf /tmp/* ~/.cache/pip || true
          df -h

      - name: Train NER + classifiers
        working-directory: fliptracker/apps/nlp-service
        run: |
          python training/train.py --epochs-ner 5 --epochs-cls 3

      - name: Collect trained models (only necessary files)
        run: |
          set -e
          cd fliptracker/apps/nlp-service
          if [ -d "models" ]; then
            find models -type f \( -name '*.pt' -o -name '*.bin' -o -name 'config.json' -o -name 'tokenizer.json' -o -name 'vocab.txt' \) | tar -czf nlp-models-${{ github.run_id }}.tar.gz -T -
          else
            echo "No models produced" && touch nlp-models-${{ github.run_id }}.tar.gz
          fi

      - name: Upload models artifact
        uses: actions/upload-artifact@v4
        with:
          name: nlp-models
          path: nlp-models-${{ github.run_id }}.tar.gz

      - name: Cleanup (post-train)
        if: always()
        run: |
          rm -f nlp-models-${{ github.run_id }}.tar.gz || true
          sudo rm -rf /tmp/* ~/.cache/pip || true
          df -h
