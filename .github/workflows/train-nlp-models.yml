- name: ðŸ› ï¸ Ultra-Aggressive Data Cleaning
        run: |
          python -c "
          import spacy, json, os, re
          from spacy.tokens import DocBin
          from spacy.util import filter_spans
          
          nlp = spacy.blank('fr')
          db = DocBin()
          input_file = 'aa.jsonl.json'
          
          with open(input_file, 'r', encoding='utf-8') as f:
              content = f.read().strip()
              try:
                  data = json.loads(content)
              except:
                  data = [json.loads(l) for l in content.split('\n') if l.strip()]

          print(f'ðŸ“¦ Analyse de {len(data)} documents...')
          valid_docs_count = 0

          for item in data:
              try:
                  raw_text = item.get('text') or (json.loads(item['line']).get('text', '') if 'line' in item else '')
                  # On nettoie les caractÃ¨res invisibles globaux
                  text = re.sub(r'[\u200b\u200c\u200d\uFEFF]', '', raw_text)
                  
                  if not text.strip(): continue
                  doc = nlp.make_doc(text)
                  ents = []
                  
                  for e in item.get('entities', []):
                      start, end, label = e['start'], e['end'], e['entity']
                      
                      # --- NETTOYAGE TOTAL (REGEX) ---
                      # On rÃ©cupÃ¨re le texte de l'entitÃ©
                      span_text = text[start:end]
                      
                      # On cherche la premiÃ¨re et la derniÃ¨re lettre/chiffre
                      match = re.search(r'[a-zA-Z0-9]', span_text)
                      if not match: continue # Pas de contenu utile
                      
                      # Ajustement du dÃ©but (start)
                      new_start = start + match.start()
                      
                      # Ajustement de la fin (end)
                      # On cherche le dernier caractÃ¨re alphanumÃ©rique
                      reverse_match = list(re.finditer(r'[a-zA-Z0-9]', span_text))
                      if not reverse_match: continue
                      new_end = start + reverse_match[-1].end()

                      span = doc.char_span(new_start, new_end, label=label, alignment_mode='contract')
                      if span and span.text.strip():
                          ents.append(span)
                  
                  doc.ents = filter_spans(ents)
                  if len(doc.ents) > 0:
                      db.add(doc)
                      valid_docs_count += 1
              except: continue

          db.to_disk('train.spacy')
          print(f'âœ… {valid_docs_count} docs validÃ©s.')
          "