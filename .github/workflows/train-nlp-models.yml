name: Train NLP models

on:
  workflow_dispatch: {}

jobs:
  train:
    name: Train CamemBERT NER + Classifiers
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: 1

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsndfile1

      - name: Install PyTorch (CPU)
        run: |
          python -m pip install --upgrade pip
          pip install --index-url https://download.pytorch.org/whl/cpu torch

      - name: Install Python requirements
        run: pip install -r fliptracker/apps/nlp-service/requirements.txt

      - name: (Optional) Export data from Firestore
        working-directory: fliptracker/apps/nlp-service
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/firebase.json
        run: |
          # Debug: print secret byte length (do not print secret value)
          echo -n "${{ secrets.FIREBASE_SERVICE_ACCOUNT }}" | wc -c > /tmp/secret_len || true
          echo "SECRET_BYTES: $(cat /tmp/secret_len)"

          # Write secret to file preserving content
          printf '%s' "${{ secrets.FIREBASE_SERVICE_ACCOUNT }}" > "${GOOGLE_APPLICATION_CREDENTIALS}" || true

          # Show file size and attributes (no content)
          echo "WROTE firebase.json size:" $(wc -c < "${GOOGLE_APPLICATION_CREDENTIALS}" || true)
          ls -l "${GOOGLE_APPLICATION_CREDENTIALS}" || true

          # Validate JSON; if invalid, attempt base64 decode and revalidate
          validate() {
            python - <<'PY'
import json,sys
path=sys.argv[1]
try:
    json.load(open(path))
    sys.exit(0)
except Exception as e:
    print('JSON_INVALID', e)
    sys.exit(1)
PY
          }

          if validate "${GOOGLE_APPLICATION_CREDENTIALS}"; then
            echo "firebase.json is valid JSON"
            python training/export_data.py
          else
            echo "firebase.json invalid JSON — trying base64 decode"
            if base64 --decode "${GOOGLE_APPLICATION_CREDENTIALS}" > "${GOOGLE_APPLICATION_CREDENTIALS}.dec" 2>/dev/null; then
              mv "${GOOGLE_APPLICATION_CREDENTIALS}.dec" "${GOOGLE_APPLICATION_CREDENTIALS}"
              echo "Decoded base64 into firebase.json; revalidating"
              if validate "${GOOGLE_APPLICATION_CREDENTIALS}"; then
                echo "Decoded file now valid JSON"
                python training/export_data.py
              else
                echo "Decoded file still invalid JSON — aborting export"
                echo "First 200 bytes of file (masked):"
                head -c 200 "${GOOGLE_APPLICATION_CREDENTIALS}" | sed -e 's/./*/g'
              fi
            else
              echo "Base64 decode failed — firebase.json is not valid base64"
              echo "Skipping export"
            fi
          fi

      - name: Prepare data (annotate)
        working-directory: fliptracker/apps/nlp-service
        run: python training/prepare_data.py

      - name: Train NER + classifiers
        working-directory: fliptracker/apps/nlp-service
        run: |
          # Short default epochs for CI; override in dispatcher if needed
          python training/train.py --epochs-ner 5 --epochs-cls 3

      - name: Collect trained models
        run: |
          set -e
          if [ -d "fliptracker/apps/nlp-service/models" ]; then
            tar -czf nlp-models-${{ github.run_id }}.tar.gz -C fliptracker/apps/nlp-service models
          else
            echo "No models produced" && touch nlp-models-${{ github.run_id }}.tar.gz
          fi

      - name: Upload models artifact
        uses: actions/upload-artifact@v4
        with:
          name: nlp-models
          path: nlp-models-${{ github.run_id }}.tar.gz

      - name: Cleanup (optional)
        if: always()
        run: rm -f nlp-models-${{ github.run_id }}.tar.gz || true
