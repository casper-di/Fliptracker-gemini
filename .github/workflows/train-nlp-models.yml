name: Train NER Model

on:
  workflow_dispatch: {}
  push:
    branches: [ main ]
    paths: [ 'fliptracker/apps/nlp-service/aa.jsonl.json' ]

jobs:
  train:
    name: ğŸ§  Train & Debug
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: fliptracker/apps/nlp-service
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install spacy

      - name: ğŸ› ï¸ Aggressive Data Cleaning
        run: |
          python -c "
          import spacy, json, os, re
          from spacy.tokens import DocBin
          from spacy.util import filter_spans
          
          # On charge le tokenizer franÃ§ais officiel
          nlp = spacy.blank('fr')
          db = DocBin()
          input_file = 'aa.jsonl.json'
          
          if not os.path.exists(input_file):
              print('âŒ Fichier introuvable'); exit(1)

          # Lecture robuste (JSON ou JSONL)
          with open(input_file, 'r', encoding='utf-8') as f:
              content = f.read().strip()
              try:
                  data = json.loads(content)
              except:
                  data = [json.loads(l) for l in content.split('\n') if l.strip()]

          print(f'ğŸ“¦ Analyse de {len(data)} documents...')
          valid_docs = 0
          skipped_ents = 0

          for item in data:
              try:
                  # Extraction du texte
                  text = item.get('text') or (json.loads(item['line']).get('text', '') if 'line' in item else '')
                  
                  # Nettoyage basique du texte (espaces insÃ©cables, etc.)
                  text = text.replace('\r', ' ').replace('\u00a0', ' ')
                  if not text.strip(): continue
                  
                  doc = nlp.make_doc(text)
                  ents = []
                  
                  for e in item.get('entities', []):
                      start, end, label = e['start'], e['end'], e['entity']
                      
                      # Si l'annotation dÃ©passe la longueur du texte (erreur courante), on coupe
                      if end > len(text): end = len(text)
                      if start >= end: continue

                      # --- MAGIE ICI ---
                      # alignment_mode='contract' : Si l'annotation coupe un mot en deux, 
                      # on ne garde que la partie 'mots entiers' Ã  l'intÃ©rieur.
                      # Cela Ã©limine 99% des erreurs E024.
                      span = doc.char_span(start, end, label=label, alignment_mode='contract')
                      
                      if span is None:
                          # L'annotation ne correspondait Ã  aucun token valide -> On jette
                          skipped_ents += 1
                      elif span.text.strip() == '':
                          # L'annotation n'Ã©tait que des espaces -> On jette
                          skipped_ents += 1
                      else:
                          ents.append(span)
                  
                  # filter_spans supprime les chevauchements (ex: Ville incluse dans Adresse)
                  doc.ents = filter_spans(ents)
                  
                  # On n'ajoute le doc que s'il a au moins une entitÃ© valide (optionnel, mais mieux pour le training)
                  if len(doc.ents) > 0:
                      db.add(doc)
                      valid_docs += 1
                      
              except Exception as err:
                  # Si un item est vraiment pourri, on l'ignore et on continue
                  continue

          db.to_disk('train.spacy')
          print(f'âœ… TerminÃ©: {valid_docs} docs valides conservÃ©s.')
          print(f'ğŸ—‘ï¸ {skipped_ents} mauvaises annotations supprimÃ©es.')
          "

      - name: ğŸ” Debug Data (Validation)
        run: |
          # Cette commande va vÃ©rifier ton fichier train.spacy AVANT l'entraÃ®nement
          # et te dire s'il reste des erreurs critiques.
          python -m spacy init config config.cfg --lang fr --pipeline ner --optimize efficiency --force
          python -m spacy debug data config.cfg --paths.train ./train.spacy --paths.dev ./train.spacy

      - name: ğŸš€ Train Model
        run: |
          python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy

      - name: ğŸ“¦ Archive Model
        uses: actions/upload-artifact@v4
        with:
          name: fliptracker-model-best
          path: fliptracker/apps/nlp-service/output/model-best