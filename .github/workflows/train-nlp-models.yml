name: Train NER Model

on:
  workflow_dispatch: {}
  push:
    branches: [ main ]
    paths: [ 'fliptracker/apps/nlp-service/aa.jsonl.json' ]

jobs:
  train:
    name: üß† Train & Generate Model
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: fliptracker/apps/nlp-service
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install spacy

      - name: üõ†Ô∏è Clean Data & Train
        run: |
          python -c "
          import spacy, json, os
          from spacy.tokens import DocBin
          from spacy.util import filter_spans
          
          nlp = spacy.blank('fr')
          db = DocBin()
          input_file = 'aa.jsonl.json'
          
          if not os.path.exists(input_file):
              print('‚ùå Fichier aa.jsonl.json introuvable'); exit(1)

          with open(input_file, 'r', encoding='utf-8') as f:
              content = f.read().strip()
              try:
                  data = json.loads(content)
              except:
                  data = [json.loads(l) for l in content.split('\n') if l.strip()]

          print(f'üì¶ Traitement de {len(data)} items...')

          for i, item in enumerate(data):
              try:
                  text = item.get('text') or (json.loads(item['line']).get('text', '') if 'line' in item else '')
                  if not text: continue
                  
                  doc = nlp.make_doc(text)
                  ents = []
                  for e in item.get('entities', []):
                      start, end, label = e['start'], e['end'], e['entity']
                      
                      # --- FIX E024: Nettoyage automatique des espaces ---
                      span_text = text[start:end]
                      while span_text.startswith((' ', '\n', '\r', '\t')) and start < end:
                          start += 1
                          span_text = text[start:end]
                      while span_text.endswith((' ', '\n', '\r', '\t')) and end > start:
                          end -= 1
                          span_text = text[start:end]
                      
                      span = doc.char_span(start, end, label=label, alignment_mode='contract')
                      if span:
                          ents.append(span)
                  
                  # filter_spans r√©sout les conflits de chevauchement d'entit√©s
                  doc.ents = filter_spans(ents)
                  db.add(doc)
              except Exception as err:
                  continue

          db.to_disk('train.spacy')
          print(f'‚úÖ {len(db)} exemples valides sauvegard√©s dans train.spacy')
          "
          
          # 1. Cr√©ation de la config
          python -m spacy init config config.cfg --lang fr --pipeline ner --optimize efficiency --force
          
          # 2. Lancement de l'entra√Ænement (CPU)
          # On utilise train.spacy pour l'entra√Ænement ET la validation vu la taille du set
          python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy

      - name: üì¶ Archive Model Artifact
        uses: actions/upload-artifact@v4
        with:
          name: fliptracker-model-best
          path: fliptracker/apps/nlp-service/output/model-best