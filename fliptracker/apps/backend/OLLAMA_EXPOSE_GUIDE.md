# üåê Exposer Ollama Local pour Backend Render

## üéØ Objectif
Permettre au backend Render d'acc√©der √† ton Ollama local via un tunnel HTTPS

---

## üì¶ M√©thode 1 : Tunnel ngrok (Temporaire, Tests)

### √âtape 1 : Installer ngrok
```bash
# Ubuntu/Debian
curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null
echo "deb https://ngrok-agent.s3.amazonaws.com buster main" | sudo tee /etc/apt/sources.list.d/ngrok.list
sudo apt update && sudo apt install ngrok

# macOS
brew install ngrok

# Ou t√©l√©charger : https://ngrok.com/download
```

### √âtape 2 : Cr√©er un compte ngrok
1. Aller sur https://dashboard.ngrok.com/signup
2. Copier ton authtoken
3. Authentifier :
```bash
ngrok config add-authtoken VOTRE_TOKEN
```

### √âtape 3 : Exposer Ollama
```bash
# Terminal 1 : D√©marrer Ollama
ollama serve

# Terminal 2 : Cr√©er le tunnel
ngrok http 11434
```

**R√©sultat** :
```
Forwarding  https://abc123.ngrok-free.app -> http://localhost:11434
```

### √âtape 4 : Configurer Render
Dans **Render Dashboard ‚Üí Backend ‚Üí Environment** :
```bash
NLP_ENABLED=true
OLLAMA_HOST=https://abc123.ngrok-free.app
```

### ‚ö†Ô∏è Limitations
- ‚ùå URL change √† chaque red√©marrage de ngrok
- ‚ùå Plan gratuit : 40 requ√™tes/minute max
- ‚ùå Latence accrue (~200ms)
- ‚ùå Pas de solution permanente

---

## üè¢ M√©thode 2 : VPS avec Ollama (Production)

### Architecture
```
Backend Render ‚Üí VPS Public (Ollama) ‚Üí R√©ponse
                 (IP fixe / domaine)
```

### √âtape 1 : Louer un VPS
**Recommandations** :
- **Hetzner CPX21** : 10‚Ç¨/mois, 3vCPU, 4GB RAM, EU (Allemagne)
- **Contabo VPS M** : 6‚Ç¨/mois, 4vCPU, 8GB RAM, EU
- **DigitalOcean Droplet** : 12$/mois, 2vCPU, 4GB RAM

### √âtape 2 : Installer Ollama sur le VPS
```bash
# Se connecter au VPS
ssh root@votre-vps-ip

# Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Configurer pour √©couter sur toutes les interfaces
sudo systemctl edit ollama

# Ajouter ces lignes :
[Service]
Environment="OLLAMA_HOST=0.0.0.0:11434"

# Red√©marrer
sudo systemctl restart ollama

# T√©l√©charger le mod√®le
ollama pull llama3.1:8b-instruct

# V√©rifier
ollama list
```

### √âtape 3 : Configurer le pare-feu
```bash
# Autoriser le port 11434
sudo ufw allow 11434/tcp
sudo ufw enable

# Tester depuis ton PC
curl http://VPS_IP:11434/api/tags
```

### √âtape 4 : (Optionnel) Ajouter un domaine
```bash
# Dans ton registrar DNS (Cloudflare, OVH, etc.)
ollama.tondomaine.com  A  VPS_IP

# Installer nginx + SSL
sudo apt install nginx certbot python3-certbot-nginx

# Configurer le proxy
sudo nano /etc/nginx/sites-available/ollama

# Contenu :
server {
    server_name ollama.tondomaine.com;
    
    location / {
        proxy_pass http://localhost:11434;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}

# Activer
sudo ln -s /etc/nginx/sites-available/ollama /etc/nginx/sites-enabled/
sudo certbot --nginx -d ollama.tondomaine.com
sudo systemctl restart nginx
```

### √âtape 5 : Configurer Render
```bash
# Render Dashboard ‚Üí Backend ‚Üí Environment
NLP_ENABLED=true
OLLAMA_HOST=https://ollama.tondomaine.com
# Ou sans domaine :
OLLAMA_HOST=http://VPS_IP:11434
```

### ‚úÖ Avantages
- ‚úÖ URL fixe permanente
- ‚úÖ Pas de limite de requ√™tes
- ‚úÖ Latence faible (~50ms EU ‚Üí EU)
- ‚úÖ Solution RGPD conforme (serveur EU)

### üí∞ Co√ªts
- VPS : 6-12‚Ç¨/mois
- Domaine (optionnel) : 10‚Ç¨/an

---

## üìä Comparaison

| M√©thode | Co√ªt | Latence | Permanence | S√©curit√© |
|---------|------|---------|------------|----------|
| **ngrok** | Gratuit | ~200ms | ‚ùå URL change | ‚ö†Ô∏è Tunnel public |
| **VPS** | 10‚Ç¨/mois | ~50ms | ‚úÖ IP fixe | ‚úÖ Contr√¥le total |
| **Local** | 0‚Ç¨ | 0ms | ‚ùå PC allum√© 24/7 | ‚ùå Pas d'acc√®s distant |

---

## üéØ Recommandation

**Pour d√©veloppement/tests** :
```bash
# Tout en local (sc√©nario 1)
Backend local + Ollama local + Frontend local
```

**Pour production** :
```bash
# Option 1 : Sans NLP (gratuit)
NLP_ENABLED=false

# Option 2 : VPS Ollama (10‚Ç¨/mois)
VPS Hetzner + domaine + SSL
```

**Pour test rapide Render** :
```bash
# ngrok temporaire (juste pour voir si √ßa marche)
ngrok http 11434
OLLAMA_HOST=https://abc123.ngrok-free.app
```
